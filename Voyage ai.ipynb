{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete this task before tomorrow evening \n"
    "https://www.voyageai.com/ \n",
    "\n",
    "Create an account using official email id.\n",
    "\n",
    "Create an api key. \n",
    "\n",
    "Use the api key to generate embeddings with different models. \n",
    "\n",
    "The output of this task would be a presentation on how the voyager ai embedding models are different from existing models in the market and how do they fare in terms of accuracy performance. Evaluate voyager ai embedding models with embedding model metrics. Discuss pro's and con's of the voyager ai models/framework.\n",
    "Perform experiments with documents, images, audios, videos, or tabular data.\n",
    "\n",
    "Documentation: https://docs.voyageai.com/docs/embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting voyageai\n",
      "  Downloading voyageai-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from voyageai) (3.9.5)\n",
      "Collecting aiolimiter (from voyageai)\n",
      "  Downloading aiolimiter-1.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from voyageai) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from voyageai) (10.3.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from voyageai) (1.10.19)\n",
      "Requirement already satisfied: requests in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from voyageai) (2.32.3)\n",
      "Requirement already satisfied: tenacity in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from voyageai) (8.5.0)\n",
      "Requirement already satisfied: tokenizers>=0.14.0 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from voyageai) (0.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=1.10.8->voyageai) (4.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tokenizers>=0.14.0->voyageai) (0.23.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->voyageai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->voyageai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->voyageai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->voyageai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->voyageai) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->voyageai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->voyageai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->voyageai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->voyageai) (2024.7.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\musha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (0.4.6)\n",
      "Downloading voyageai-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading aiolimiter-1.2.1-py3-none-any.whl (6.7 kB)\n",
      "Installing collected packages: aiolimiter, voyageai\n",
      "Successfully installed aiolimiter-1.2.1 voyageai-0.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\musha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\musha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\musha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install voyageai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"VOYAGEAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit hit! Retrying in 20 seconds... (Attempt 1/3)\n",
      "Rate limit hit! Retrying in 20 seconds... (Attempt 2/3)\n",
      "\n",
      "Cosine Similarity using voyage-02:\n",
      "Similarity between text 1 and text 2: 0.5966\n",
      "Similarity between text 1 and text 3: 0.8269\n",
      "Similarity between text 1 and text 4: 0.7197\n",
      "Similarity between text 1 and text 5: 0.7628\n",
      "Similarity between text 1 and text 6: 0.7771\n",
      "Similarity between text 2 and text 3: 0.5951\n",
      "Similarity between text 2 and text 4: 0.5740\n",
      "Similarity between text 2 and text 5: 0.6052\n",
      "Similarity between text 2 and text 6: 0.6047\n",
      "Similarity between text 3 and text 4: 0.7126\n",
      "Similarity between text 3 and text 5: 0.7873\n",
      "Similarity between text 3 and text 6: 0.7772\n",
      "Similarity between text 4 and text 5: 0.7018\n",
      "Similarity between text 4 and text 6: 0.6786\n",
      "Similarity between text 5 and text 6: 0.7545\n",
      "\n",
      "Cosine Similarity using voyage-01:\n",
      "Similarity between text 1 and text 2: 0.5813\n",
      "Similarity between text 1 and text 3: 0.7804\n",
      "Similarity between text 1 and text 4: 0.5970\n",
      "Similarity between text 1 and text 5: 0.7042\n",
      "Similarity between text 1 and text 6: 0.7011\n",
      "Similarity between text 2 and text 3: 0.5365\n",
      "Similarity between text 2 and text 4: 0.5235\n",
      "Similarity between text 2 and text 5: 0.5283\n",
      "Similarity between text 2 and text 6: 0.5346\n",
      "Similarity between text 3 and text 4: 0.5824\n",
      "Similarity between text 3 and text 5: 0.6884\n",
      "Similarity between text 3 and text 6: 0.7176\n",
      "Similarity between text 4 and text 5: 0.6192\n",
      "Similarity between text 4 and text 6: 0.5462\n",
      "Similarity between text 5 and text 6: 0.6556\n"
     ]
    }
   ],
   "source": [
    "import voyageai\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from voyageai.error import RateLimitError\n",
    "\n",
    "# Initialize client with API key\n",
    "client = voyageai.Client(api_key=\"apikey\")  # Replace with your actual API key\n",
    "\n",
    "def get_embeddings(texts, model=\"voyage-02\", retries=3, wait_time=20):\n",
    "    \"\"\"\n",
    "    Fetches embeddings for a list of texts from the Voyage AI API with retry handling.\n",
    "    \n",
    "    Parameters:\n",
    "        texts (list): List of input texts.\n",
    "        model (str): The Voyage AI model to use.\n",
    "        retries (int): Number of retries on rate limit errors.\n",
    "        wait_time (int): Time to wait before retrying (seconds).\n",
    "\n",
    "    Returns:\n",
    "        List of embeddings or None if all retries fail.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.embed(texts=texts, model=model)\n",
    "            return response.embeddings  # Return list of embeddings\n",
    "        except RateLimitError:\n",
    "            print(f\"Rate limit hit! Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{retries})\")\n",
    "            time.sleep(wait_time)\n",
    "    print(f\"Failed to get embeddings after {retries} retries.\")\n",
    "    return None\n",
    "\n",
    "sample_texts = [\n",
    "    \"Artificial intelligence is transforming the world of technology.\",\n",
    "    \"virat kohli is a cricket player\",\n",
    "    \"Deep learning and machine learning are subsets of artificial intelligence.\",\n",
    "    \"The sky is blue, and the ocean is vast.\",\n",
    "    \"Voyage AI models provide state-of-the-art embeddings.\",\n",
    "    \"Natural Language Processing helps machines understand human language.\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "# List of models to compare\n",
    "models = [\"voyage-02\", \"voyage-01\"]\n",
    "\n",
    "# Generate embeddings for each model\n",
    "embeddings = {model: get_embeddings(sample_texts, model) for model in models}\n",
    "\n",
    "from itertools import combinations\n",
    "# Compute cosine similarity for all pairs\n",
    "for model in models:\n",
    "    print(f\"\\nCosine Similarity using {model}:\")\n",
    "    for (i, j) in combinations(range(len(sample_texts)), 2):\n",
    "        similarity = cosine_similarity([embeddings[model][i]], [embeddings[model][j]])[0][0]\n",
    "        print(f\"Similarity between text {i+1} and text {j+1}: {similarity:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Text Document Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voyageai\n",
    "\n",
    "def get_document_embedding(text, model=\"voyage-02\"):\n",
    "    client = voyageai.Client(api_key=\"YOUR_API_KEY\")\n",
    "    response = client.embed(texts=[text], model=model)\n",
    "    return response.embeddings[0]\n",
    "\n",
    "# Example: Comparing two text documents\n",
    "doc1 = \"\"\"Artificial intelligence is a transformative technology reshaping industries.\"\"\"\n",
    "doc2 = \"\"\"Machine learning, a subset of AI, enables computers to learn from data.\"\"\"\n",
    "\n",
    "embedding1 = get_document_embedding(doc1)\n",
    "embedding2 = get_document_embedding(doc2)\n",
    "\n",
    "similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "print(f\"Cosine Similarity between documents: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Image Embeddings (Using CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "# Load CLIP model\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=\"cpu\")\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.encode_image(image)\n",
    "    return embedding.numpy()\n",
    "\n",
    "# Example: Compare two images\n",
    "img1_emb = get_image_embedding(\"image1.jpg\")\n",
    "img2_emb = get_image_embedding(\"image2.jpg\")\n",
    "\n",
    "similarity = cosine_similarity(img1_emb, img2_emb)[0][0]\n",
    "print(f\"Image similarity: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Audio Embeddings (Using OpenAIâ€™s Whisper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor\n",
    "\n",
    "model_name = \"facebook/wav2vec2-base-960h\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2Model.from_pretrained(model_name)\n",
    "\n",
    "def get_audio_embedding(audio_path):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    input_values = processor(waveform, return_tensors=\"pt\", sampling_rate=sample_rate).input_values\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_values).last_hidden_state.mean(dim=1)\n",
    "    return embedding.numpy()\n",
    "\n",
    "# Example: Compare two audio files\n",
    "audio1_emb = get_audio_embedding(\"audio1.wav\")\n",
    "audio2_emb = get_audio_embedding(\"audio2.wav\")\n",
    "\n",
    "similarity = cosine_similarity(audio1_emb, audio2_emb)[0][0]\n",
    "print(f\"Audio similarity: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Video Embeddings (Using Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_frame(video_path, frame_no=100):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame if ret else None\n",
    "\n",
    "# Example: Extract frames and compare\n",
    "frame1 = extract_frame(\"video1.mp4\")\n",
    "frame2 = extract_frame(\"video2.mp4\")\n",
    "\n",
    "# Use CLIP or any other image embedding model for comparison\n",
    "# For simplicity, let's use a simple Euclidean distance metric\n",
    "def compare_frames(frame1, frame2):\n",
    "    # Convert frames to grayscale and normalize\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    gray1 = gray1 / 255.0\n",
    "    gray2 = gray2 / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Tabular Data Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0130719980224967, 0.0007462683133780956, -0.06340689957141876, -0.019397083669900894, -0.020350156351923943]\n"
     ]
    }
   ],
   "source": [
    "import voyageai\n",
    "\n",
    "client = voyageai.Client(api_key=\"apikey\")\n",
    "\n",
    "text = \"Artificial intelligence is transforming the world of technology...\"\n",
    "embedding = client.embed(texts=[text], model=\"voyage-02\").embeddings[0]\n",
    "\n",
    "print(embedding[:5])  # Print first 5 dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f903a39d9c04d94afd531d55600c0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\musha\\.cache\\huggingface\\hub\\models--Salesforce--blip-image-captioning-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bddf49bf05464da65cb9d8b7ef9d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fe928c1c4a488586a303a072778935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98595b539064dfa9f4ada9a818d02d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4811ac57c3e40a594199883d3c86973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfd341b48514913921d638b48c72f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2337ee3f5a03478fad5c87c9e8c4316b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: a couple standing next to an elephant\n",
      "Embedding: [0.015264528803527355, 0.027475425973534584, -0.03771424666047096, -0.02656930685043335, -0.03808571770787239]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import voyageai\n",
    "from PIL import Image\n",
    "\n",
    "# Load BLIP model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Load image\n",
    "image = Image.open(\"img.png\")\n",
    "\n",
    "# Generate caption\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "caption = model.generate(**inputs)\n",
    "caption_text = processor.decode(caption[0], skip_special_tokens=True)\n",
    "\n",
    "# Get embedding for caption\n",
    "client = voyageai.Client(api_key=\"pa-q5iO23zBxoGURDboAgB_2xajMBx\")\n",
    "embedding = client.embed(texts=[caption_text], model=\"voyage-02\").embeddings[0]\n",
    "\n",
    "print(\"Caption:\", caption_text)\n",
    "print(\"Embedding:\", embedding[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import voyageai\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"audio.mp3\")\n",
    "\n",
    "# Extract transcript\n",
    "text = result[\"text\"]\n",
    "\n",
    "# Get embedding\n",
    "client = voyageai.Client(api_key=\"your_api_key\")\n",
    "embedding = client.embed(texts=[text], model=\"voyage-02\").embeddings[0]\n",
    "\n",
    "print(\"Transcript:\", text)\n",
    "print(\"Embedding:\", embedding[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import voyageai\n",
    "\n",
    "# Transcribe audio from video\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"video.mp4\")\n",
    "\n",
    "# Get text embedding\n",
    "client = voyageai.Client(api_key=\"your_api_key\")\n",
    "embedding = client.embed(texts=[result[\"text\"]], model=\"voyage-02\").embeddings[0]\n",
    "\n",
    "print(\"Embedding:\", embedding[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   review                                          embedding\n",
      "0          Great product!  [0.024344058707356453, -0.003227048087865114, ...\n",
      "1                 Not bad  [-0.01091188658028841, 0.0044401357881724834, ...\n",
      "2  Worst experience ever!  [0.0100494883954525, -0.00510049844160676, -0....\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import voyageai\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"review\": [\"Great product!\", \"Not bad\", \"Worst experience ever!\"]\n",
    "})\n",
    "\n",
    "client = voyageai.Client(api_key=\"pa-q5iO23zBxoGURD\")\n",
    "df[\"embedding\"] = df[\"review\"].apply(lambda x: client.embed(texts=[x], model=\"voyage-02\").embeddings[0])\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ijk\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
